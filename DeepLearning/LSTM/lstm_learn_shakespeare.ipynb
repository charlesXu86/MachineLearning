{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hdf5 is not supported on this machine (please install/reinstall h5py for optimal experience)\ncurses is not supported on this machine (please install/reinstall curses for an optimal experience)\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "No module named 'tensorflow.contrib.rnn.python.ops.core_rnn'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mE:\\devtools\\python3.5.3\\lib\\site-packages\\tflearn\\layers\\recurrent.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrnn_cell_impl\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_rnn_cell\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdynamic_rnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_drnn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatic_rnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_rnn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbidirectional_dynamic_rnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_brnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mcore_rnn_cell\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_rnn_cell\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'rnn_cell_impl'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-e759f0edf81a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmoves\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtflearn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtflearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\devtools\\python3.5.3\\lib\\site-packages\\tflearn\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# Predefined ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnormalization\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\devtools\\python3.5.3\\lib\\site-packages\\tflearn\\layers\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mnormalization\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbatch_normalization\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_response_normalization\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mregression\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mrecurrent\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlstm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgru\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msimple_rnn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbidirectional_rnn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mBasicRNNCell\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBasicLSTMCell\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGRUCell\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0membedding_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0membedding\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\devtools\\python3.5.3\\lib\\site-packages\\tflearn\\layers\\recurrent.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m# Fix for TF 1.1.0 and under\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore_rnn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstatic_rnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_rnn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatic_bidirectional_rnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_brnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrnn_cell_impl\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_rnn_cell\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdynamic_rnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_drnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcore_rnn_cell\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named 'tensorflow.contrib.rnn.python.ops.core_rnn'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "from six.moves import urllib\n",
    "\n",
    "import tflearn\n",
    "from tflearn.data_utils import *\n",
    "\n",
    "path = \"shakespeare_input.txt\"\n",
    "char_idx_file = 'char_idx.pickle'\n",
    "\n",
    "if not os.path.isfile(path):\n",
    "    urllib.request.urlretrieve(\"https://raw.githubusercontent.com/tflearn/tflearn.github.io/master/resources/shakespeare_input.txt\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading previous char_idx\n",
      "Vectorizing text...\n",
      "Text total length: 4,573,338\n",
      "Distinct chars   : 67\n",
      "Total sequences  : 1,524,438\n"
     ]
    }
   ],
   "source": [
    "maxlen = 25\n",
    "\n",
    "char_idx = None\n",
    "if os.path.isfile(char_idx_file):\n",
    "  print('Loading previous char_idx')\n",
    "  char_idx = pickle.load(open(char_idx_file, 'rb'))\n",
    "\n",
    "X, Y, char_idx = \\\n",
    "    textfile_to_semi_redundant_sequences(path, seq_maxlen=maxlen, redun_step=3,\n",
    "                                         pre_defined_char_idx=char_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(char_idx, open(char_idx_file,'wb'))\n",
    "\n",
    "g = tflearn.input_data([None, maxlen, len(char_idx)])\n",
    "g = tflearn.lstm(g, 512, return_seq=True)\n",
    "g = tflearn.dropout(g, 0.5)\n",
    "g = tflearn.lstm(g, 512, return_seq=True)\n",
    "g = tflearn.dropout(g, 0.5)\n",
    "g = tflearn.lstm(g, 512)\n",
    "g = tflearn.dropout(g, 0.5)\n",
    "g = tflearn.fully_connected(g, len(char_idx), activation='softmax')\n",
    "g = tflearn.regression(g, optimizer='adam', loss='categorical_crossentropy',\n",
    "                       learning_rate=0.001)\n",
    "\n",
    "m = tflearn.SequenceGenerator(g, dictionary=char_idx,\n",
    "                              seq_maxlen=maxlen,\n",
    "                              clip_gradients=5.0,\n",
    "                              checkpoint_path='model_shakespeare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 107189  | total loss: \u001b[1m\u001b[32m1.34488\u001b[0m\u001b[0m | time: 561.687s\n",
      "| Adam | epoch: 010 | loss: 1.34488 -- iter: 1371904/1371994\n",
      "Training Step: 107190  | total loss: \u001b[1m\u001b[32m1.35806\u001b[0m\u001b[0m | time: 600.688s\n",
      "| Adam | epoch: 010 | loss: 1.35806 | val_loss: 1.28005 -- iter: 1371994/1371994\n",
      "--\n",
      "INFO:tensorflow:/home/wei/Documents/DeepLearningCourseCodes/model_shakespeare-107190 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "WARNING:tensorflow:Error encountered when serializing layer_tensor/LSTM.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef.\n",
      "'list' object has no attribute 'name'\n",
      "WARNING:tensorflow:Error encountered when serializing layer_tensor/Dropout.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef.\n",
      "'list' object has no attribute 'name'\n",
      "WARNING:tensorflow:Error encountered when serializing layer_tensor/LSTM_1.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef.\n",
      "'list' object has no attribute 'name'\n",
      "-- TESTING...\n",
      "-- Test with temperature of 1.0 --\n",
      "ou see'st with peril I have content, which reason'd let me clear?\n",
      "\n",
      "GORENIL:\n",
      "And what you have stop this occasion is better blame?\n",
      "\n",
      "PAROLLES:\n",
      "Why, with the enument in question not, peace, my father knight.\n",
      "I'll so know the night, being done,\n",
      "And villany, my doom, is the commanded tarteries.\n",
      "\n",
      "WARWICK:\n",
      "My son is thy place and quickly.\n",
      "How now, where wates, let Choefight and walks be bones;\n",
      "Our flock, if he have partled there than we\n",
      "enteral Mancanimone.\n",
      "\n",
      "PAGE:\n",
      "Carsing which not to seek it,\n",
      "Not yet worth and sow, beards of himself.\n",
      "\n",
      "POINS:\n",
      "All his cities, thou wilt there?\n",
      "\n",
      "DUGLET:\n",
      "My man for, goes but yet I do\n",
      "loathe, and\n",
      "-- Test with temperature of 0.5 --\n",
      "ou see'st with peril I have been to keep me to him.\n",
      "\n",
      "DON ADRIANO DE ARMADO:\n",
      "There is no fair course and honest sins\n",
      "And be the villain of the care of she is these death,\n",
      "And the speedy prince were so soon of the house.\n",
      "\n",
      "SIR TOBY BELCH:\n",
      "Thou shalt stand do the love of her soul,\n",
      "The last she will come a man to the rest,\n",
      "They so service and enemy.\n",
      "\n",
      "MARCIUS:\n",
      "I hope the name of France?\n",
      "\n",
      "FALSTAFF:\n",
      "Why, what is the father may have the large of a stand.\n",
      "\n",
      "DEMETRIUS:\n",
      "And I would not be my soul to him to him: and I have the love\n",
      "And be it in his fight.\n",
      "\n",
      "ALBANY:\n",
      "What was this to the heart;\n",
      "The night of the most prince and my most\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    seed = random_sequence_from_textfile(path, maxlen)\n",
    "    m.fit(X, Y, validation_set=0.1, batch_size=128,\n",
    "          n_epoch=1, run_id='shakespeare')\n",
    "    print(\"-- TESTING...\")\n",
    "    print(\"-- Test with temperature of 1.0 --\")\n",
    "    print(m.generate(600, temperature=1.0, seq_seed=seed))\n",
    "    print(\"-- Test with temperature of 0.5 --\")\n",
    "    print(m.generate(600, temperature=0.5, seq_seed=seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
